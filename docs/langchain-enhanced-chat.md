# LangChain & LangGraph Enhanced Chat System

## ðŸš€ Tá»•ng quan

Há»‡ thá»‘ng chat sá»­ dá»¥ng **LangChain** vÃ  **LangGraph** Ä‘á»ƒ cung cáº¥p tráº£i nghiá»‡m há»™i thoáº¡i AI tiÃªn tiáº¿n vá»›i:

- **Workflow Management**: LangGraph Ä‘á»ƒ quáº£n lÃ½ luá»“ng há»™i thoáº¡i
- **Tool Calling**: TÃ­ch há»£p cÃ¡c tools cho plant identification vÃ  care advice
- **Memory Management**: PostgreSQL + LangChain memory cho context dÃ i háº¡n
- **Vector Search**: Pinecone vá»›i LangChain vector stores
- **Streaming Responses**: Real-time response streaming
- **Advanced Agents**: OpenAI functions agent vá»›i custom tools

## ðŸ—ï¸ Kiáº¿n trÃºc

```mermaid
graph TD
    User[User Input] --> LG[LangGraph Workflow]
    LG --> AI[Analyze Input]
    LG --> TC[Tool Calling]
    LG --> RC[Retrieve Context]
    LG --> GR[Generate Response]
    LG --> UM[Update Memory]

    TC --> PT[Plant Tools]
    PT --> PI[Plant ID]
    PT --> PC[Plant Care]
    PT --> UP[User Preferences]

    RC --> VS[Vector Search]
    RC --> CH[Chat History]
    RC --> UPF[User Profile]

    GR --> OpenAI[GPT-4o]
    UM --> PG[PostgreSQL]
    UM --> PN[Pinecone]
```

## ðŸ› ï¸ Components

### LangGraph Workflow

**Nodes**:
- `analyze_input`: PhÃ¢n tÃ­ch intent vÃ  entities tá»« user input
- `retrieve_context`: Láº¥y context tá»« vector store vÃ  chat history
- `generate_response`: Táº¡o response cÃ¡ nhÃ¢n hÃ³a vá»›i LLM
- `update_memory`: Cáº­p nháº­t memory vÃ  user profile
- `tools`: Node Ä‘á»ƒ thá»±c thi cÃ¡c tools

**Flow Logic**:
```python
START â†’ analyze_input â†’ [tools?] â†’ retrieve_context â†’ generate_response â†’ update_memory â†’ END
```

### Custom Tools

1. **PlantIdentificationTool**
   - Nháº­n diá»‡n cÃ¢y tá»« hÃ¬nh áº£nh
   - TÃ­ch há»£p vá»›i DiagnosisService
   - Tráº£ vá» plant species vÃ  confidence score

2. **get_plant_care_info**
   - Láº¥y thÃ´ng tin chÄƒm sÃ³c comprehensive
   - Dá»±a trÃªn plant species vÃ  issue cá»¥ thá»ƒ
   - Knowledge base integration

3. **save_user_preference**
   - LÆ°u preferences cho personalization
   - Update user profile trong database
   - Cáº£i thiá»‡n future interactions

### Memory Management

- **ConversationBufferWindowMemory**: Quáº£n lÃ½ conversation context
- **PostgresChatMessageHistory**: Persistent chat history
- **User Profile**: LÆ°u trá»¯ preferences vÃ  learning patterns

## ðŸš€ API Endpoints

### Chat Endpoints (v3)

**Base URL**: `/api/v3/chat`

#### POST `/` - Main Chat
```json
{
  "message": "What's wrong with my monstera?",
  "session_id": "optional-session-id",
  "image_data": "base64-encoded-image",
  "stream": true
}
```

**Response** (streaming):
```
data: Here's what I can see...
data: Your monstera appears to have...
data: [DONE]
```

#### POST `/sessions` - Create Session
```json
{
  "title": "Monstera Care Discussion"
}
```

#### GET `/sessions` - List Sessions
```json
[
  {
    "session_id": "uuid",
    "title": "Monstera Care",
    "created_at": "2025-08-14T10:00:00Z",
    "message_count": 15,
    "is_active": true
  }
]
```

#### GET `/sessions/{session_id}/messages` - Get Messages
```json
{
  "session_id": "uuid",
  "messages": [
    {
      "role": "user",
      "content": "Help with my plant",
      "created_at": "2025-08-14T10:00:00Z"
    }
  ]
}
```

#### GET `/tools` - Available Tools
```json
[
  {
    "name": "plant_identification",
    "description": "Identify plants from images",
    "parameters": ["image_data"]
  }
]
```

#### GET `/workflow/status` - Workflow Info
```json
{
  "workflow_enabled": true,
  "nodes": ["analyze_input", "retrieve_context", "generate_response"],
  "features": ["Tool calling", "Memory management", "Personalization"]
}
```

## ðŸŽ¯ Key Features

### 1. Advanced Conversation Flows
- **State Management**: ConversationState vá»›i full context
- **Conditional Logic**: Intelligent routing based on input analysis
- **Error Handling**: Robust error recovery vÃ  fallbacks

### 2. Tool Integration
- **Dynamic Tool Selection**: Based on intent analysis
- **Parallel Execution**: Multiple tools cÃ³ thá»ƒ cháº¡y Ä‘á»“ng thá»i
- **Result Integration**: Tool outputs Ä‘Æ°á»£c integrate vÃ o response

### 3. Personalization Engine
- **User Profiling**: Experience level, communication style, plant collection
- **Adaptive Responses**: Tailored based on user history
- **Learning**: System learns tá»« interactions Ä‘á»ƒ improve

### 4. Memory & Context
- **Short-term**: Conversation buffer cho current session
- **Long-term**: PostgreSQL storage cho persistent memory
- **Vector Memory**: Pinecone cho semantic context retrieval

## ðŸ”§ Configuration

### Environment Variables
```env
# LangChain Settings
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your-langsmith-key

# Model Configuration
OPENAI_MODEL=gpt-4o
EMBEDDING_MODEL=text-embedding-3-small

# Workflow Settings
MAX_ITERATIONS=10
TOOL_TIMEOUT=30
STREAMING_ENABLED=true
```

### Customization

**Custom Prompt Template**:
```python
def _create_system_prompt(self, user_profile, plant_context):
    return f"""You are PlantBot specialized in {user_profile['expertise']}.

    Current context: {plant_context}
    User preferences: {user_profile['style']}
    """
```

**Custom Tools**:
```python
@tool
async def my_custom_tool(parameter: str) -> str:
    """Custom tool description"""
    # Implementation
    return result
```

## ðŸ“Š Performance & Monitoring

### Metrics
- **Response Time**: Average processing time per request
- **Tool Usage**: Frequency of each tool Ä‘Æ°á»£c sá»­ dá»¥ng
- **User Satisfaction**: Based on feedback scores
- **Conversation Length**: Average messages per session

### Monitoring
- **LangSmith**: Tracing vÃ  debugging workflows
- **Custom Logging**: Detailed logging cho má»—i workflow step
- **Error Tracking**: Comprehensive error monitoring

## ðŸ§ª Testing

```bash
# Test LangChain chat
curl -X POST http://localhost:5000/api/v3/chat/ \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-token" \
  -d '{
    "message": "Help identify this plant",
    "stream": true
  }'

# Test tools endpoint
curl http://localhost:5000/api/v3/chat/tools

# Test workflow status
curl http://localhost:5000/api/v3/chat/workflow/status
```

## ðŸš€ Deployment

1. **Install Dependencies**: `uv sync`
2. **Configure Environment**: Set LangChain vÃ  OpenAI keys
3. **Run Migrations**: Database setup cho chat tables
4. **Start Server**: `uv run fastapi dev src/main.py`
5. **Test API**: Access `/docs` Ä‘á»ƒ test endpoints

## ðŸŽ‰ Benefits

### So vá»›i Enhanced Chat (v2):
- **More Structured**: LangGraph workflows vs linear processing
- **Better Tool Integration**: Native LangChain tool support
- **Advanced Memory**: Multiple memory types vá»›i vector search
- **Monitoring**: Built-in tracing vá»›i LangSmith
- **Extensibility**: Easier Ä‘á»ƒ add new tools vÃ  workflows

### Use Cases:
- **Plant Diagnosis**: Multi-step analysis vá»›i tool calling
- **Care Planning**: Sequential workflows cho comprehensive advice
- **Learning Conversations**: Adaptive responses based on user progress
- **Expert Consultations**: Advanced reasoning vá»›i multiple information sources

Há»‡ thá»‘ng LangChain mang láº¡i tráº£i nghiá»‡m chat AI tiÃªn tiáº¿n nháº¥t cho Plant Assistant! ðŸŒ±ðŸ¤–

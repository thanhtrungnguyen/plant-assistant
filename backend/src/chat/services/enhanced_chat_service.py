"""Enhanced chat service with PostgreSQL storage (Pinecone optional)."""
from typing import List, Optional, Dict, Any
import uuid
from datetime import datetime
import logging

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.memory import ConversationBufferWindowMemory
from langchain.schema import HumanMessage, AIMessage
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from src.core.config import settings
from src.chat.models.chat_models import ChatSession, ChatMessage
from src.chat.schemas import ChatRequest, ChatResponse

logger = logging.getLogger(__name__)


class EnhancedChatService:
    """Enhanced chat service with PostgreSQL storage."""

    def __init__(self):
        """Initialize the enhanced chat service."""
        self.llm = None
        self.embeddings = None
        self.memory = None
        self._initialized = False
        self._sessions = {}  # For compatibility with old interface

    async def initialize(self):
        """Initialize LangChain components."""
        if self._initialized:
            return

        try:
            # Initialize OpenAI
            if not settings.OPENAI_API_KEY:
                logger.warning("OpenAI API key not configured")
                return

            self.llm = ChatOpenAI(
                model=settings.OPENAI_MODEL,
                api_key=settings.OPENAI_API_KEY,
                temperature=0.7,
                max_tokens=2000
            )

            self.embeddings = OpenAIEmbeddings(
                model=settings.EMBEDDING_MODEL,
                api_key=settings.OPENAI_API_KEY
            )

            # Initialize memory
            self.memory = ConversationBufferWindowMemory(
                k=settings.MAX_CHAT_HISTORY,
                return_messages=True
            )

            self._initialized = True
            logger.info("Enhanced chat service initialized successfully")

        except Exception as e:
            logger.error(f"Failed to initialize enhanced chat service: {e}")
            # Don't raise, allow service to work without AI

    async def create_chat_session(self, user_id: int, session: AsyncSession) -> str:
        """Create a new chat session."""
        session_id = str(uuid.uuid4())

        new_session = ChatSession(
            id=session_id,
            user_id=user_id,
            created_at=datetime.utcnow(),
            updated_at=datetime.utcnow()
        )

        session.add(new_session)
        await session.commit()

        logger.info(f"Created chat session {session_id} for user {user_id}")
        return session_id

    async def get_chat_history(self, session_id: str, session: AsyncSession) -> List[ChatMessage]:
        """Get chat history for a session."""
        query = (
            select(ChatMessage)
            .where(ChatMessage.session_id == session_id)
            .order_by(ChatMessage.created_at)
        )

        result = await session.execute(query)
        messages = result.scalars().all()

        return list(messages)

    async def save_message(
        self,
        session_id: str,
        content: str,
        role: str,
        session: AsyncSession,
        metadata: Optional[Dict[str, Any]] = None
    ) -> ChatMessage:
        """Save a message to the database."""
        message = ChatMessage(
            id=str(uuid.uuid4()),
            session_id=session_id,
            content=content,
            role=role,
            message_metadata=metadata or {},
            created_at=datetime.utcnow()
        )

        session.add(message)
        await session.commit()

        return message

    async def generate_response(
        self,
        session_id: str,
        user_message: str,
        db_session: AsyncSession
    ) -> str:
        """Generate AI response using LLM with context."""
        if not self._initialized:
            await self.initialize()

        # For demo purposes, if no OpenAI key, provide intelligent responses
        if not self.llm:
            return self._get_intelligent_fallback_response(user_message)

        try:
            # Load chat history
            history = await self.get_chat_history(session_id, db_session)

            # Build context from history
            context_messages = []
            for msg in history[-settings.MAX_CHAT_HISTORY:]:
                if msg.role == "user":
                    context_messages.append(HumanMessage(content=msg.content))
                elif msg.role == "assistant":
                    context_messages.append(AIMessage(content=msg.content))

            # Build system prompt
            system_prompt = """B·∫°n l√† tr·ª£ l√Ω chƒÉm s√≥c c√¢y th√¥ng minh. H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát v√† cung c·∫•p th√¥ng tin h·ªØu √≠ch v·ªÅ:
- ChƒÉm s√≥c c√¢y c·∫£nh
- Ch·∫©n ƒëo√°n b·ªánh c√¢y
- T∆∞·ªõi n∆∞·ªõc v√† b√≥n ph√¢n
- √Ånh s√°ng v√† nhi·ªát ƒë·ªô
- C√°ch tr·ªìng v√† nh√¢n gi·ªëng

H√£y tr·∫£ l·ªùi m·ªôt c√°ch th√¢n thi·ªán v√† d·ªÖ hi·ªÉu."""

            # Prepare messages
            messages = [
                ("system", system_prompt)
            ]

            # Add conversation history
            for msg in context_messages:
                if isinstance(msg, HumanMessage):
                    messages.append(("human", msg.content))
                elif isinstance(msg, AIMessage):
                    messages.append(("assistant", msg.content))

            # Add current user message
            messages.append(("human", user_message))

            # Generate response
            response = await self.llm.ainvoke(messages)

            return response.content

        except Exception as e:
            logger.error(f"Error generating response: {e}")
            return self._get_intelligent_fallback_response(user_message)

    def _get_intelligent_fallback_response(self, user_message: str) -> str:
        """Generate intelligent fallback response when AI is not available."""
        message_lower = user_message.lower()

        # Specific plant responses
        if "ƒëu ƒë·ªß" in message_lower or "du du" in message_lower:
            return """üå± **ChƒÉm s√≥c c√¢y ƒêu ƒë·ªß:**

üåû **√Ånh s√°ng**: C√¢y ƒëu ƒë·ªß c·∫ßn √°nh s√°ng m·∫∑t tr·ªùi tr·ª±c ti·∫øp √≠t nh·∫•t 6 gi·ªù/ng√†y
üíß **T∆∞·ªõi n∆∞·ªõc**: T∆∞·ªõi ƒë·ªÅu ƒë·∫∑n, gi·ªØ ƒë·∫•t ·∫©m nh∆∞ng tho√°t n∆∞·ªõc t·ªët
üå°Ô∏è **Nhi·ªát ƒë·ªô**: Th√≠ch h·ª£p 20-30¬∞C, kh√¥ng ch·ªãu ƒë∆∞·ª£c l·∫°nh
üåø **ƒê·∫•t**: ƒê·∫•t t∆°i x·ªëp, gi√†u dinh d∆∞·ª°ng, pH 6.0-7.0
ü•ó **B√≥n ph√¢n**: NPK 20-10-20 m·ªói 2-3 th√°ng

‚ö†Ô∏è **L∆∞u √Ω**:
- Tr√°nh √∫ng n∆∞·ªõc g√¢y th·ªëi r·ªÖ
- C·∫Øt t·ªâa l√° gi√† v√† c√†nh y·∫øu
- Ph√≤ng ch·ªëng s√¢u b·ªánh nh∆∞ r·ªáp, b·ªç trƒ©

B·∫°n c√≥ c√¢u h·ªèi c·ª• th·ªÉ n√†o v·ªÅ c√¢y ƒëu ƒë·ªß kh√¥ng?"""

        # Other plant-specific responses
        plant_responses = {
            "hoa h·ªìng": "üåπ Hoa h·ªìng c·∫ßn √°nh s√°ng m·∫°nh, ƒë·∫•t tho√°t n∆∞·ªõc t·ªët, v√† b√≥n ph√¢n th∆∞·ªùng xuy√™n...",
            "lan": "üå∫ Lan c·∫ßn ·∫©m ƒë·ªô cao, √°nh s√°ng gi√°n ti·∫øp, v√† gi√° th·ªÉ tho√°ng...",
            "sen ƒë√°": "üåµ Sen ƒë√° ∆∞a n·∫Øng, √≠t n∆∞·ªõc, ƒë·∫•t c√°t tho√°t n∆∞·ªõc t·ªët...",
            "c√¢y xanh": "üåø C√¢y xanh trong nh√† c·∫ßn √°nh s√°ng gi√°n ti·∫øp, t∆∞·ªõi khi ƒë·∫•t kh√¥...",
        }

        for plant, response in plant_responses.items():
            if plant in message_lower:
                return response

        # General care topics
        if "v√†ng l√°" in message_lower:
            return """üçÇ **Nguy√™n nh√¢n l√° v√†ng:**

üíß **T∆∞·ªõi n∆∞·ªõc sai**: Qu√° nhi·ªÅu ho·∫∑c qu√° √≠t n∆∞·ªõc
‚òÄÔ∏è **Thi·∫øu √°nh s√°ng**: Kh√¥ng ƒë·ªß nƒÉng l∆∞·ª£ng quang h·ª£p
üåø **Thi·∫øu dinh d∆∞·ª°ng**: ƒê·∫∑c bi·ªát thi·∫øu Nit∆°
üå°Ô∏è **Thay ƒë·ªïi m√¥i tr∆∞·ªùng**: Nhi·ªát ƒë·ªô, ·∫©m ƒë·ªô kh√¥ng ·ªïn ƒë·ªãnh

**C√°ch kh·∫Øc ph·ª•c:**
- Ki·ªÉm tra ƒë·ªô ·∫©m ƒë·∫•t tr∆∞·ªõc khi t∆∞·ªõi
- Di chuy·ªÉn c√¢y ƒë·∫øn ch·ªó s√°ng h∆°n
- B√≥n ph√¢n NPK c√¢n b·∫±ng
- C·∫Øt b·ªè l√° v√†ng"""

        if "t∆∞·ªõi n∆∞·ªõc" in message_lower:
            return """üíß **H∆∞·ªõng d·∫´n t∆∞·ªõi n∆∞·ªõc:**

‚è∞ **Th·ªùi gian**: S√°ng s·ªõm ho·∫∑c chi·ªÅu m√°t
üå°Ô∏è **T·∫ßn su·∫•t**: Khi ƒë·∫•t kh√¥ 2-3cm d∆∞·ªõi b·ªÅ m·∫∑t
üí¶ **L∆∞·ª£ng n∆∞·ªõc**: ƒê·ªß ·∫©m, tr√°nh √∫ng n∆∞·ªõc

**D·∫•u hi·ªáu c·∫ßn t∆∞·ªõi:**
- ƒê·∫•t kh√¥, c·ª©ng
- L√° h√©o, kh√¥ng cƒÉng b√≥ng
- Ch·∫≠u nh·∫π khi nh·∫•c l√™n"""

        # Default response
        return """Xin ch√†o! T√¥i l√† tr·ª£ l√Ω chƒÉm s√≥c c√¢y. üå±

T√¥i c√≥ th·ªÉ gi√∫p b·∫°n v·ªÅ:
- ChƒÉm s√≥c c√°c lo·∫°i c√¢y c·ª• th·ªÉ
- Ch·∫©n ƒëo√°n b·ªánh c√¢y
- T∆∞·ªõi n∆∞·ªõc, b√≥n ph√¢n
- √Ånh s√°ng v√† m√¥i tr∆∞·ªùng

H√£y m√¥ t·∫£ chi ti·∫øt v·∫•n ƒë·ªÅ ho·∫∑c lo·∫°i c√¢y b·∫°n quan t√¢m!"""

    async def process_chat(self, request):
        """Process chat request - interface compatibility method"""
        # Mock database session and user_id for compatibility
        from contextlib import asynccontextmanager

        @asynccontextmanager
        async def mock_db_session():
            # Return a mock session that doesn't actually save to DB
            class MockSession:
                async def execute(self, query):
                    # Mock the result object with scalars method
                    class MockResult:
                        def scalars(self):
                            class MockScalars:
                                def all(self):
                                    return []  # Return empty list for chat history
                            return MockScalars()
                    return MockResult()

                async def commit(self): pass
                async def scalar(self, query): return None
                async def refresh(self, obj): pass
                def add(self, obj): pass

            yield MockSession()

        # If no database available, use intelligent fallback
        if not hasattr(self, '_mock_fallback_only'):
            try:
                async with mock_db_session() as db:
                    return await self.process_chat_message(
                        request=request,
                        user_id=1,  # Mock user ID
                        db_session=db
                    )
            except Exception:
                pass

        # Fallback to intelligent response without database
        fallback_response = self._get_intelligent_fallback_response(request.message)
        session_id = request.session_id or str(uuid.uuid4())

        return {
            "message": fallback_response,
            "session_id": session_id,
            "timestamp": datetime.utcnow(),
            "suggestions": [],
            "plant_identified": None,
            "confidence_score": None
        }

    async def process_chat_message(
        self,
        request: ChatRequest,
        user_id: int,
        db_session: AsyncSession
    ) -> ChatResponse:
        """Process a chat message and return response."""
        try:
            # Create session if not provided
            session_id = request.session_id
            if not session_id:
                session_id = await self.create_chat_session(user_id, db_session)

            # Save user message
            await self.save_message(
                session_id=session_id,
                content=request.message,
                role="user",
                session=db_session
            )

            # Generate AI response
            ai_response = await self.generate_response(
                session_id=session_id,
                user_message=request.message,
                db_session=db_session
            )

            # Save AI response
            await self.save_message(
                session_id=session_id,
                content=ai_response,
                role="assistant",
                session=db_session
            )

            return ChatResponse(
                session_id=session_id,
                message=ai_response,
                timestamp=datetime.utcnow()
            )

        except Exception as e:
            logger.error(f"Error processing chat message: {e}")
            return ChatResponse(
                session_id=request.session_id or "error",
                message="Xin l·ªói, t√¥i g·∫∑p l·ªói khi x·ª≠ l√Ω tin nh·∫Øn c·ªßa b·∫°n.",
                timestamp=datetime.utcnow()
            )


# Global service instance
enhanced_chat_service = EnhancedChatService()
